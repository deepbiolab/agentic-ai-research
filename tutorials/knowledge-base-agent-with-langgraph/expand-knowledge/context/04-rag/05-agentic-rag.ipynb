{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Agentic Decisions into RAG Pipelines\n",
    "\n",
    "### Overview\n",
    "\n",
    "This demo expands a basic RAG (Retrieval-Augmented Generation) pipeline to include **agentic decision-making**. The system dynamically decides whether to rely on retrieved documents or perform **live web research** depending on the quality of retrieved information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from typing import List, Dict\n",
    "\n",
    "# LLM related\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# RAG related\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Tools related\n",
    "from langchain_core.tools import tool\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# Graph related\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline Preparing Data for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Documents Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-era-of-experience.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Vector Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_fn = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(\n",
    "    collection_name=\"demo\",\n",
    "    embedding_function=embeddings_fn\n",
    ")\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define State Schema\n",
    "\n",
    "A custom state is defined including:\n",
    "\n",
    "- `search_required`: a yes/no flag determining whether a web search is necessary.\n",
    "- Other standard RAG fields (messages, question, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    search_required: str = \"NO\"\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Retrieve Node\n",
    "\n",
    "- Performs a similarity search using the vector store.\n",
    "- Retrieves documents related to the input question and stores them in state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    question = state[\"question\"]\n",
    "    retrieved_docs = vector_store.similarity_search(question)\n",
    "    return {\"documents\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Augment Node\n",
    "\n",
    "- If web search is not required, retrieved documents are passed to the LLM for direct answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(state: State):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    \n",
    "    template = ChatPromptTemplate([\n",
    "        (\"system\", \"You are an assistant for question-answering tasks.\"),\n",
    "        (\"human\", \"Use the following pieces of retrieved context to answer the question. \"\n",
    "                \"If you don't know the answer, just say that you don't know. \" \n",
    "                \"Use three sentences maximum and keep the answer concise. \"\n",
    "                \"\\n# Question: \\n-> {question} \"\n",
    "                \"\\n# Context: \\n-> {context} \"\n",
    "                \"\\n# Answer: \"),\n",
    "    ])\n",
    "\n",
    "    messages = template.invoke(\n",
    "        {\"context\": docs_content, \"question\": question}\n",
    "    ).to_messages()\n",
    "\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Generate Node\n",
    "\n",
    "- Final output generation based on the selected source of context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "def generate(state: State):\n",
    "    ai_message = llm.invoke(state[\"messages\"])\n",
    "    return {\"answer\": ai_message.content, \"messages\": ai_message}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluator Node\n",
    "\n",
    "- Uses an LLM chain with a prompt asking:\n",
    "    - *\"Based on retrieved documents, is a web search required? Answer 'yes' or 'no'.\"*\n",
    "- The LLM's response sets the `search_required` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(state: State):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    \n",
    "    template = ChatPromptTemplate([\n",
    "        (\"system\", \"You are an assistant for evaluating context.\"),\n",
    "        (\"human\", \"Use the following pieces of retrieved context to determine if an \" \n",
    "                  \"additional search is required. If the context is relevant to the \" \n",
    "                  \"question, your response should be 'NO', i.e. no need for search. \"\n",
    "                  \"If the context is not relevant, say 'YES', i.e. search the web for an answer. \" \n",
    "                  \"Don't explain anything, if it's to search the web, say YES, otherwise, NO. \"\n",
    "                  \"\\n# Question: \\n-> {question} \"\n",
    "                  \"\\n# Context: \\n-> {context} \"\n",
    "                  \"\\n# Answer: \"),\n",
    "    ])\n",
    "\n",
    "    chain = template | llm | StrOutputParser()\n",
    "\n",
    "    search_required = chain.invoke(\n",
    "        {\"context\": docs_content, \"question\": question}\n",
    "    )\n",
    "\n",
    "    return {\"search_required\": search_required}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def web_search(question:str)->Dict:\n",
    "    \"\"\"\n",
    "    Return top search results for a given search query\n",
    "    \"\"\"\n",
    "    tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "    response = tavily_client.search(question)\n",
    "    return response\n",
    "\n",
    "llm_with_tools = llm.bind_tools([web_search])\n",
    "\n",
    "search = ToolNode([web_search])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Researcher Node\n",
    "\n",
    "- If web search is needed, the researcher node uses Tavily’s web search tool.\n",
    "- Searches the web and updates messages with search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher(state: State):\n",
    "    question = state[\"question\"]\n",
    "    messages = state[\"messages\"]\n",
    "    if not messages:\n",
    "        human_message = HumanMessage(\n",
    "            \"Conduct a web research to findout the answer to the following question: \"\n",
    "            f\"```{question}```\"\n",
    "        )\n",
    "        messages = [human_message]\n",
    "    \n",
    "    ai_message = llm_with_tools.invoke(messages)\n",
    "    messages.append(ai_message)\n",
    "    return {\"messages\": messages, \"answer\": ai_message.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Router"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move to Local RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_router(state: MessagesState):\n",
    "    search_required = state[\"search_required\"]\n",
    "    if search_required.lower() == \"yes\":\n",
    "        return \"researcher\"\n",
    "\n",
    "    return \"augment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move to Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_router(state: MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"web_search\"\n",
    "\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agentic RAG Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"augment\", augment)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"evaluator\", evaluator)\n",
    "workflow.add_node(\"researcher\", researcher)\n",
    "workflow.add_node(\"web_search\", search)\n",
    "\n",
    "# START -> retrieve\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "\n",
    "# retrieve -> evaluator\n",
    "workflow.add_edge(\"retrieve\", \"evaluator\")\n",
    "\n",
    "# evaluator -> augment or researcher\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"evaluator\", \n",
    "    path=rag_router, \n",
    "    path_map=[\"augment\", \"researcher\"]\n",
    ")\n",
    "\n",
    "# ############ PATH 1: Local RAG #################\n",
    "# augment -> generate\n",
    "workflow.add_edge(\"augment\", \"generate\")\n",
    "\n",
    "# generate -> END\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# ############ PATH 2: Web Search #################\n",
    "# researcher -> web_search or END\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"researcher\", \n",
    "    path=tool_router, \n",
    "    path_map=[\"web_search\", END]\n",
    ")\n",
    "\n",
    "# web_search -> researcher\n",
    "workflow.add_edge(\"web_search\", \"researcher\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(\n",
    "#     Image(\n",
    "#         graph.get_graph().draw_mermaid_png()\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path 1: Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = graph.invoke(\n",
    "    input={\"question\": \"How many eras for deep learning history?\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YES'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"search_required\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The search results did not provide a specific answer to the question of how many eras there are in the history of deep learning. However, they did mention significant milestones and developments in deep learning, indicating that the history can be divided into several key periods or \"eras.\"\\n\\nTo summarize, the history of deep learning can generally be categorized into the following eras:\\n\\n1. **Early Foundations (1940s-1980s)**: This era includes the initial concepts of neural networks and early models.\\n2. **AI Winters (1980s-1990s)**: A period marked by reduced funding and interest in AI and neural networks.\\n3. **Resurgence and Breakthroughs (2000s)**: The development of more advanced algorithms and the introduction of GPUs for faster processing.\\n4. **Deep Learning Revolution (2012-Present)**: Marked by significant breakthroughs in applications such as image and speech recognition, largely due to advancements in deep learning techniques.\\n\\nFor a more detailed exploration, you can refer to the articles found in the search results, such as [A Brief History of Deep Learning](https://www.dataversity.net/brief-history-deep-learning/) and [The Evolution of Deep Learning: A Comprehensive Timeline](https://dataspaceinsights.com/the-evolution-of-deep-learning-a-comprehensive-timeline/).'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Conduct a web research to findout the answer to the following question: ```How many eras for deep learning history?```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  web_search (call_YhpoWqQH7igUQ5qM2vJtcTGj)\n",
      " Call ID: call_YhpoWqQH7igUQ5qM2vJtcTGj\n",
      "  Args:\n",
      "    question: How many eras for deep learning history?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: web_search\n",
      "\n",
      "{\"query\": \"How many eras for deep learning history?\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"Brief History of Deep Learning from 1943-2019 [Timeline] - MLK\", \"url\": \"https://machinelearningknowledge.ai/brief-history-of-deep-learning/\", \"content\": \"Deep Learning Yet it will lay the foundation for artificial neural network & deep learning. Sepp Hochreiter identifies the problem of vanishing gradient which can make the learning of deep neural network extremely slow and almost impractical. It is a type of recurrent neural network architecture which will go on to revolutionize deep learning in decades to come. Geoffrey Hinton, Ruslan Salakhutdinov, Osindero and Teh publishes the paper “A fast learning algorithm for deep belief nets” in which they stacked multiple RBMs together in layers and called them Deep Belief Networks. This means that now, apart from GPU, deep learning community has another tool to avoid issues of longer and impractical training times of deep neural network. https://en.wikipedia.org/wiki/Convolutional_neural_network#History http://www.andreykurenkov.com/writing/ai/a-brief-history-of-neural-nets-and-deep-learning/ https://en.wikipedia.org/wiki/Deep_belief_network https://www.quora.com/What-does-Andrew-Ng-think-about-Deep-Learning\", \"score\": 0.41094592, \"raw_content\": null}, {\"title\": \"The Evolution of Deep Learning: A Comprehensive Timeline\", \"url\": \"https://dataspaceinsights.com/the-evolution-of-deep-learning-a-comprehensive-timeline/\", \"content\": \"We use cookies to help you navigate efficiently and perform certain functions. Functional cookies help perform certain functionalities like sharing the content of the website on social media platforms, collecting feedback, and other third-party features. Deep Learning Deep Learning The evolution of deep learning has been a remarkable journey, encompassing the development of neural networks and numerous AI breakthroughs. CNNs are specialized neural networks for processing grid-like data, such as images, and have since become a cornerstone of deep learning applications. Modern AI Breakthroughs and the Future of Deep Learning (2010-Present) The deep learning history is a fascinating tale of neural networks, AI breakthroughs, and technological advancements that have shaped the world. Tagged: AI breakthroughs Deep Learning history Neural Networks timeline\", \"score\": 0.34826875, \"raw_content\": null}, {\"title\": \"A Brief History of Deep Learning - DATAVERSITY\", \"url\": \"https://www.dataversity.net/brief-history-deep-learning/\", \"content\": \"Deep Learning, is a more evolved branch of machine learning, and uses layers of algorithms to process data, and imitate the thinking process, or to develop abstractions. This time is also when the second AI winter (1985-90s) kicked in, which also effected research for neural networks and deep learning. The next significant evolutionary step for deep learning took place in 1999, when computers started becoming faster at processing data and GPU (graphics processing units) were developed. Neural networks also have the advantage of continuing to improve as more training data is added. The free-spirited project explored the difficulties of “unsupervised learning.” Deep learning uses “supervised learning,” meaning the convolutional neural net is trained using labeled data (think images from ImageNet).\", \"score\": 0.3085969, \"raw_content\": null}, {\"title\": \"A Short History Of Deep Learning — Everyone Should Read\", \"url\": \"https://bernardmarr.com/a-short-history-of-deep-learning-everyone-should-read/\", \"content\": \"Er hat über 2 Millionen Social-Media-Follower, 1 Million Newsletter-Abonnenten und wurde von LinkedIn als einer der Top-5-Business-Influencer der Welt und von Xing als Top Mind 2021 ausgezeichnet. Deep learning is based on the concept of artificial neural networks, or computational systems that mimic the way the human brain functions. 1989: Scientists were able to create algorithms that used deep neural networks, but training times for the systems were measured in days, making them impractical for real-world use. 2009: NIPS Workshop on Deep Learning for Speech Recognition discovers that with a large enough data set, the neural networks don’t need pre-training, and the error rates drop significantly. And Google’s deep learning algorithm discovers cats.\", \"score\": 0.29319245, \"raw_content\": null}, {\"title\": \"A Journey Through the History of Deep Learning - Medium\", \"url\": \"https://medium.com/@limbusapna3/a-journey-through-the-history-of-deep-learning-7033f1ff21c0\", \"content\": \"Deep Learning Revolution (2012) In 2011, the speed of GPUs increased significantly, enabling the training of convolutional neural networks without layer-by-layer pre-training.\", \"score\": 0.20721509, \"raw_content\": null}], \"response_time\": 1.78}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The search results did not provide a specific answer to the question of how many eras there are in the history of deep learning. However, they did mention significant milestones and developments in deep learning, indicating that the history can be divided into several key periods or \"eras.\"\n",
      "\n",
      "To summarize, the history of deep learning can generally be categorized into the following eras:\n",
      "\n",
      "1. **Early Foundations (1940s-1980s)**: This era includes the initial concepts of neural networks and early models.\n",
      "2. **AI Winters (1980s-1990s)**: A period marked by reduced funding and interest in AI and neural networks.\n",
      "3. **Resurgence and Breakthroughs (2000s)**: The development of more advanced algorithms and the introduction of GPUs for faster processing.\n",
      "4. **Deep Learning Revolution (2012-Present)**: Marked by significant breakthroughs in applications such as image and speech recognition, largely due to advancements in deep learning techniques.\n",
      "\n",
      "For a more detailed exploration, you can refer to the articles found in the search results, such as [A Brief History of Deep Learning](https://www.dataversity.net/brief-history-deep-learning/) and [The Evolution of Deep Learning: A Comprehensive Timeline](https://dataspaceinsights.com/the-evolution-of-deep-learning-a-comprehensive-timeline/).\n"
     ]
    }
   ],
   "source": [
    "for message in output[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path 2: Local RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = graph.invoke(\n",
    "    input={\"question\": \"What's the difference of Planning and Reasoning?\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NO'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"search_required\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are an assistant for question-answering tasks.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. \n",
      "# Question: \n",
      "-> What's the difference of Planning and Reasoning? \n",
      "# Context: \n",
      "-> Planning and Reasoning\n",
      "Will the era of experience change the way that agents plan and reason? Recently, there has been significant\n",
      "progress using LLMs that can reason, or “think” with language [23, 14, 10], by following a chain of thought\n",
      "before outputting a response [16]. Conceptually, LLMs can act as a universal computer [30]: an LLM can\n",
      "append tokens into its own context, allowing it to execute arbitrary algorithms before outputting a final result.\n",
      "In the era of human data, these reasoning methods have been explicitly designed to imitate human thought\n",
      "processes. For example, LLMs have been prompted to emit human-like chains of thought [16], imitate traces\n",
      "of human thinking [42], or to reinforce steps of thinking that match human examples [18]. The reasoning\n",
      "process may be fine-tuned further to produce thinking traces that match the correct answer, as determined by\n",
      "human experts [44].\n",
      "\n",
      "Planning and Reasoning\n",
      "Will the era of experience change the way that agents plan and reason? Recently, there has been significant\n",
      "progress using LLMs that can reason, or “think” with language [23, 14, 10], by following a chain of thought\n",
      "before outputting a response [16]. Conceptually, LLMs can act as a universal computer [30]: an LLM can\n",
      "append tokens into its own context, allowing it to execute arbitrary algorithms before outputting a final result.\n",
      "In the era of human data, these reasoning methods have been explicitly designed to imitate human thought\n",
      "processes. For example, LLMs have been prompted to emit human-like chains of thought [16], imitate traces\n",
      "of human thinking [42], or to reinforce steps of thinking that match human examples [18]. The reasoning\n",
      "process may be fine-tuned further to produce thinking traces that match the correct answer, as determined by\n",
      "human experts [44].\n",
      "\n",
      "Planning and Reasoning\n",
      "Will the era of experience change the way that agents plan and reason? Recently, there has been significant\n",
      "progress using LLMs that can reason, or “think” with language [23, 14, 10], by following a chain of thought\n",
      "before outputting a response [16]. Conceptually, LLMs can act as a universal computer [30]: an LLM can\n",
      "append tokens into its own context, allowing it to execute arbitrary algorithms before outputting a final result.\n",
      "In the era of human data, these reasoning methods have been explicitly designed to imitate human thought\n",
      "processes. For example, LLMs have been prompted to emit human-like chains of thought [16], imitate traces\n",
      "of human thinking [42], or to reinforce steps of thinking that match human examples [18]. The reasoning\n",
      "process may be fine-tuned further to produce thinking traces that match the correct answer, as determined by\n",
      "human experts [44].\n",
      "\n",
      "world model might predict how a user’s heart rate or sleep patterns might subsequently change following this\n",
      "action, as well as predicting future dialogue with the user. This allows the agent to plan [36, 29] directly in\n",
      "terms of its own actions and their causal effect upon the world. As the agent continues to interact with the\n",
      "world throughout its stream of experience, its dynamics model is continually updated to correct any errors\n",
      "in its predictions. Given a world model, an agent may apply scalable planning methods that improve the\n",
      "predicted performance of the agent.\n",
      "Planning and reasoning methods are not mutually exclusive: an agent may apply internal LLM computa-\n",
      "tions to select each action during planning, or to simulate and evaluate the consequences of those actions.\n",
      "Why Now?\n",
      "Learning from experience is not new. Reinforcement learning systems have previously mastered a large \n",
      "# Answer: \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Planning involves determining a sequence of actions to achieve a specific goal, while reasoning refers to the cognitive process of thinking through problems and drawing conclusions. Both processes can be integrated, as agents may use reasoning to inform their planning decisions. In essence, planning is about \"what to do,\" and reasoning is about \"how to think about it.\"\n"
     ]
    }
   ],
   "source": [
    "for message in output[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "- **Dynamic decision-making** inside a RAG workflow.\n",
    "- **Fallback to web search** when knowledge gaps are detected.\n",
    "- **Agentic behavior**: LLM assesses context sufficiency and adapts.\n",
    "- **Efficient resource use**: Web search is only triggered when necessary.\n",
    "- Adding agentic decisions to RAG pipelines increases reliability and adaptability.\n",
    "- Blending offline retrieval with online search creates more robust AI systems.\n",
    "- This modular, decision-driven design is foundational for advanced AI agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
