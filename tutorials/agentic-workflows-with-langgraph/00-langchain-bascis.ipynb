{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab5eb61e",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62402062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from typing import List, Dict\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# LangChain Core\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from langchain_core.prompts import (\n",
    "    PromptTemplate,\n",
    "    FewShotPromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_core.runnables import (\n",
    "    RunnableSequence,\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "# LangChain Output Parsers\n",
    "from langchain.output_parsers.datetime import DatetimeOutputParser\n",
    "from langchain.output_parsers.boolean import BooleanOutputParser\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "# LangChain RAG Components\n",
    "from langchain_community.document_loaders.arxiv import ArxivLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# LangChain Tools\n",
    "from langchain.tools import tool\n",
    "from langchain_core.tools.structured import StructuredTool\n",
    "from langchain_core.output_parsers.openai_tools import parse_tool_calls\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082424ec",
   "metadata": {},
   "source": [
    "### Bascis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b262550",
   "metadata": {},
   "source": [
    "#### Simple LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647cd215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"AlphaFold is an artificial intelligence program developed by DeepMind, a subsidiary of Alphabet Inc. It is designed to predict the three-dimensional structures of proteins based on their amino acid sequences. Proteins are essential biological molecules that perform a wide range of functions in living organisms, and their function is closely related to their structure. \\n\\nAlphaFold gained significant attention for its performance in the Critical Assessment of protein Structure Prediction (CASP) competition, where it demonstrated remarkable accuracy in predicting protein structures, often rivaling experimental methods such as X-ray crystallography and cryo-electron microscopy. The program uses deep learning techniques to analyze patterns in known protein structures and make predictions about new ones.\\n\\nThe implications of AlphaFold's capabilities are vast, potentially accelerating research in fields such as drug discovery, disease understanding, and synthetic biology by providing insights into protein functions and interactions. In July 2021, DeepMind released the predicted structures of the human proteome, further contributing to the scientific community's understanding of protein biology.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 200, 'prompt_tokens': 13, 'total_tokens': 213, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'stop', 'logprobs': None} id='run-9f47bec2-e8b9-4198-ac41-d08d480afeee-0' usage_metadata={'input_tokens': 13, 'output_tokens': 200, 'total_tokens': 213}\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "print(llm.invoke(\"What is Alphafold?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e1c24",
   "metadata": {},
   "source": [
    "#### Chat Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78297ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaFold is an artificial intelligence program developed by DeepMind that predicts protein structures with high accuracy. It uses deep learning techniques to model the three-dimensional shapes of proteins based on their amino acid sequences. The primary applications of AlphaFold include:\n",
      "\n",
      "1. **Understanding Protein Function**: By predicting the structure of proteins, researchers can gain insights into their functions and how they interact with other molecules, which is crucial for understanding biological processes.\n",
      "\n",
      "2. **Drug Discovery**: Accurate protein structures can aid in the design of new drugs by allowing scientists to identify potential binding sites and optimize drug candidates for better efficacy and reduced side effects.\n",
      "\n",
      "3. **Disease Research**: AlphaFold can help in understanding the structural basis of diseases caused by protein misfolding or mutations, such as Alzheimer's disease or cystic fibrosis.\n",
      "\n",
      "4. **Synthetic Biology**: Researchers can use AlphaFold to design new proteins with specific functions, which can be applied in various fields, including bioengineering and therapeutics.\n",
      "\n",
      "5. **Comparative Genomics**: By predicting structures for proteins from different organisms, scientists can study evolutionary relationships and functional conservation across species.\n",
      "\n",
      "Overall, AlphaFold represents a significant advancement in computational biology, providing tools that can accelerate research in various areas of life sciences and biotechnology.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You are a Data Scientist in biotech\"),\n",
    "    HumanMessage(\"What is AlphaFold used for?\"),\n",
    "]\n",
    "ai_message = llm.invoke(messages)\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9b7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFdiffusion is a generative model used for protein design and structure prediction. It leverages diffusion models to generate novel protein sequences and structures by learning from existing protein data. RFdiffusion can help in tasks such as designing proteins with specific functions, optimizing protein stability, and exploring the vast sequence space of proteins to identify potential candidates for therapeutic or industrial applications. Its ability to generate high-quality protein structures makes it a valuable tool in the fields of biotechnology and drug discovery.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You are a Data Scientist in biotech\"),\n",
    "    HumanMessage(\"What is AlphaFold used for?\"),\n",
    "    AIMessage(\"AlphaFold is used to predict the structure of proteins.\"),\n",
    "    HumanMessage(\"What is RFdiffusion used for?\"),\n",
    "]\n",
    "\n",
    "ai_message = llm.invoke(messages)\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b4bba",
   "metadata": {},
   "source": [
    "#### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0541cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='What is Alphafold used for?'\n"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=\"What is {tool} used for?\",\n",
    ")\n",
    "\n",
    "print(prompt_template.invoke({\"tool\": \"Alphafold\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69c775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaFold is an artificial intelligence program developed by DeepMind that predicts protein structures with high accuracy. It is primarily used for:\n",
      "\n",
      "1. **Protein Structure Prediction**: AlphaFold can predict the three-dimensional structures of proteins based on their amino acid sequences. This is crucial for understanding how proteins function and interact with other molecules.\n",
      "\n",
      "2. **Biological Research**: Researchers use AlphaFold to gain insights into various biological processes, including enzyme function, protein-protein interactions, and the mechanisms of diseases.\n",
      "\n",
      "3. **Drug Discovery**: By providing accurate protein structures, AlphaFold aids in the design of new drugs and therapeutic interventions by helping scientists understand the target proteins involved in diseases.\n",
      "\n",
      "4. **Genomics and Proteomics**: AlphaFold can assist in interpreting genomic data by predicting the structures of proteins encoded by newly sequenced genes, which can lead to discoveries in functional genomics.\n",
      "\n",
      "5. **Synthetic Biology**: It can be used to design new proteins with specific functions, which has applications in biotechnology and synthetic biology.\n",
      "\n",
      "Overall, AlphaFold represents a significant advancement in computational biology and has the potential to accelerate research across various fields in life sciences.\n"
     ]
    }
   ],
   "source": [
    "ai_message = llm.invoke(prompt_template.invoke({\"tool\": \"Alphafold\"}))\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fca142",
   "metadata": {},
   "source": [
    "#### Few Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa50e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: A bioreactor is seeded with 2×10⁶ cells/mL. The cells double every 24 hours. What will the cell density be after 3 days?\n",
      "Thought: The cells double once every 24 hours. In 3 days (72 hours), there are 3 doublings: 2×10⁶ × 2³ = 2×10⁶ × 8 = 1.6×10⁷ cells/mL.\n",
      "Response: 1.6×10⁷ cells/mL\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"input\": \"A bioreactor is seeded with 2×10⁶ cells/mL. The cells double every 24 hours. What will the cell density be after 3 days?\",\n",
    "        \"thought\": \"The cells double once every 24 hours. In 3 days (72 hours), there are 3 doublings: 2×10⁶ × 2³ = 2×10⁶ × 8 = 1.6×10⁷ cells/mL.\",\n",
    "        \"output\": \"1.6×10⁷ cells/mL\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"A downstream purification step has a yield of 80%. If the initial protein amount is 5 grams, how much protein remains after this step?\",\n",
    "        \"thought\": \"The yield is 80%, so the remaining protein is 5 g × 0.8 = 4 g.\",\n",
    "        \"output\": \"4 grams\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"A fermentation process uses glucose and produces ethanol and CO₂. If 10 moles of glucose are consumed, how many moles of ethanol are produced, assuming the theoretical yield (2 moles ethanol per mole glucose)?\",\n",
    "        \"thought\": \"The stoichiometry is 1 glucose → 2 ethanol. Thus, 10 moles glucose × 2 = 20 moles ethanol.\",\n",
    "        \"output\": \"20 moles ethanol\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"A cell culture produces 150 mg of antibody in 5 liters over 48 hours. What is the average production rate in mg/L/hour?\",\n",
    "        \"thought\": \"Production rate = total amount / (volume × time) = 150 mg / (5 L × 48 h) = 150 / 240 = 0.625 mg/L/h.\",\n",
    "        \"output\": \"0.625 mg/L/h\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"A fed-batch process starts with 1 liter at 10 g/L substrate. 2 liters of feed at 20 g/L are added. What is the final substrate concentration (assuming perfect mixing and no consumption)?\",\n",
    "        \"thought\": \"Initial substrate: 1 L × 10 g/L = 10 g. Feed: 2 L × 20 g/L = 40 g. Total substrate = 10 + 40 = 50 g. Final volume = 1 + 2 = 3 L. Final concentration = 50 g / 3 L ≈ 16.67 g/L.\",\n",
    "        \"output\": \"16.67 g/L\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    template=\"Question: {input}\\nThought: {thought}\\nResponse: {output}\"\n",
    ")\n",
    "\n",
    "print(example_prompt.invoke(examples[0]).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2112a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the final concentration after dilution, we can use the dilution formula:\n",
      "\n",
      "\\[ C_1V_1 = C_2V_2 \\]\n",
      "\n",
      "Where:\n",
      "- \\( C_1 \\) is the initial concentration (0.1 M)\n",
      "- \\( V_1 \\) is the initial volume (50 mL)\n",
      "- \\( C_2 \\) is the final concentration (unknown)\n",
      "- \\( V_2 \\) is the final volume (200 mL)\n",
      "\n",
      "Rearranging the formula to solve for \\( C_2 \\):\n",
      "\n",
      "\\[ C_2 = \\frac{C_1V_1}{V_2} \\]\n",
      "\n",
      "Substituting the known values:\n",
      "\n",
      "\\[ C_2 = \\frac{0.1 \\, \\text{M} \\times 50 \\, \\text{mL}}{200 \\, \\text{mL}} \\]\n",
      "\n",
      "Calculating:\n",
      "\n",
      "\\[ C_2 = \\frac{5 \\, \\text{mmol}}{200 \\, \\text{mL}} = 0.025 \\, \\text{M} \\]\n",
      "\n",
      "Thus, the final concentration of the solution is:\n",
      "\n",
      "**0.025 M NaCl**\n"
     ]
    }
   ],
   "source": [
    "prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question: {input}\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "response = llm.invoke(\n",
    "    prompt_template.invoke(\n",
    "        {\n",
    "            \"input\": \"What is the final concentration of a solution that starts with 50 mL of 0.1 M NaCl and is diluted to 200 mL?\"\n",
    "        }\n",
    "    )\n",
    ")\n",
    "print(response.content)  # Response should be 0.025 M NaCl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05628404",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b488da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c6a97",
   "metadata": {},
   "source": [
    "#### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8392b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(message: str, memory: List):\n",
    "    memory.append(HumanMessage(content=message))\n",
    "    chunks = []\n",
    "    try:\n",
    "        for chunk in llm.stream(memory):\n",
    "            chunks.append(chunk)\n",
    "            print(chunk.content, end=\"|\", flush=True)\n",
    "            if len(chunks) % 12 == 0:\n",
    "                print(\"\\n\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n______________________________\")\n",
    "\n",
    "    result = \"\".join([chunk.content for chunk in chunks])\n",
    "    memory.append(AIMessage(content=result))\n",
    "\n",
    "\n",
    "def resume(memory: List):\n",
    "    print(\"\\nResuming from last interaction...\\n\")\n",
    "    play(\n",
    "        message=\"If your last message is not complete, continue \"\n",
    "        \"after the last word. If it's complete, just output __END__\",\n",
    "        memory=memory,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46ea9b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|To| find| the| final| concentration| of| the| solution| after| dilution|,|\n",
      "\n",
      " you| can| use| the| dilution| formula|:\n",
      "\n",
      "|\\|[\n",
      "|C|_|1|\n",
      "\n",
      " V|_|1| =| C|_|2| V|_|2|\n",
      "|\\|\n",
      "\n",
      "]\n",
      "\n",
      "|where|:\n",
      "|-| \\(|C|_|1|\\|)| is| the|\n",
      "\n",
      " initial| concentration| (|0|.|1| M|),\n",
      "|-| \\(|V|_|\n",
      "\n",
      "1|\\|)| is| the| initial| volume| (|50| m|L|),\n",
      "|\n",
      "\n",
      "-| \\(|C|_|2|\\|)| is| the| final| concentration| (|\n",
      "\n",
      "what| we| want| to| find|),\n",
      "|-| \\(|V|_|2|\\|\n",
      "\n",
      ")| is| the| final| volume| (|200| m|L|).\n",
      "\n",
      "|Plug|ging|\n",
      "\n",
      " in| the| values|:\n",
      "\n",
      "|\\|[\n",
      "|(|0|.|1| \\|,|\n",
      "\n",
      " \\|text|{|M|})| \\|times| (|50| \\|,| \\|\n",
      "\n",
      "text|{|m|L|})| =| C|_|2| \\|times| (|\n",
      "\n",
      "200| \\|,| \\|text|{|m|L|})\n",
      "|\\|]\n",
      "\n",
      "|Calcul|\n",
      "\n",
      "ating| the| left| side|:\n",
      "\n",
      "|\\|[\n",
      "|5| \\|,| \\|text|\n",
      "\n",
      "{|M| m|L|}| =| C|_|2| \\|times| |\n",
      "\n",
      "200| \\|,| \\|text|{|m|L|}\n",
      "|\\|]\n",
      "\n",
      "|Now|\n",
      "\n",
      ",| solve| for| \\(|C|_|2|\\|):\n",
      "\n",
      "|\\|[\n",
      "|C|\n",
      "\n",
      "_|2| =| \\|frac|{|5| \\|,| \\|text|{|\n",
      "\n",
      "M| m|L|}}|{|200| \\|,| \\|text|{|m|\n",
      "\n",
      "L|}}| =| |0|.|025| \\|,| \\|text|{|\n",
      "\n",
      "M|}\n",
      "|\\|]\n",
      "\n",
      "|Thus|,| the| final| concentration| of| the| solution|\n",
      "\n",
      " after| dilution| is| **|0|.|025| M|**|.||"
     ]
    }
   ],
   "source": [
    "memory = []\n",
    "\n",
    "message = \"What is the final concentration of a solution that starts with 50 mL of 0.1 M NaCl and is diluted to 200 mL?\"\n",
    "\n",
    "play(message, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04e16184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resuming from last interaction...\n",
      "\n",
      "|__|END|__||"
     ]
    }
   ],
   "source": [
    "resume(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23bdff6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the final concentration of a solution that starts with 50 mL of 0.1 M NaCl and is diluted to 200 mL?'),\n",
       " AIMessage(content='To find the final concentration of the solution after dilution, you can use the dilution formula:\\n\\n\\\\[\\nC_1 V_1 = C_2 V_2\\n\\\\]\\n\\nwhere:\\n- \\\\(C_1\\\\) is the initial concentration (0.1 M),\\n- \\\\(V_1\\\\) is the initial volume (50 mL),\\n- \\\\(C_2\\\\) is the final concentration (what we want to find),\\n- \\\\(V_2\\\\) is the final volume (200 mL).\\n\\nPlugging in the values:\\n\\n\\\\[\\n(0.1 \\\\, \\\\text{M}) \\\\times (50 \\\\, \\\\text{mL}) = C_2 \\\\times (200 \\\\, \\\\text{mL})\\n\\\\]\\n\\nCalculating the left side:\\n\\n\\\\[\\n5 \\\\, \\\\text{M mL} = C_2 \\\\times 200 \\\\, \\\\text{mL}\\n\\\\]\\n\\nNow, solve for \\\\(C_2\\\\):\\n\\n\\\\[\\nC_2 = \\\\frac{5 \\\\, \\\\text{M mL}}{200 \\\\, \\\\text{mL}} = 0.025 \\\\, \\\\text{M}\\n\\\\]\\n\\nThus, the final concentration of the solution after dilution is **0.025 M**.'),\n",
       " HumanMessage(content=\"If your last message is not complete, continue after the last word. If it's complete, just output __END__\"),\n",
       " AIMessage(content='__END__')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81b078",
   "metadata": {},
   "source": [
    "#### Streaming Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c74fac28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f3/_6ts5bqd5s30t0mq76kjkdxc0000gn/T/ipykernel_3992/3603337307.py:2: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  async for event in llm.astream_events(\"hello\", version=\"v2\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming...\n",
      "Chat model chunk: ''\n",
      "Chat model chunk: 'Hello'\n",
      "Chat model chunk: '!'\n",
      "Chat model chunk: ' How'\n",
      "Chat model chunk: ' can'\n",
      "Chat model chunk: ' I'\n",
      "Chat model chunk: ' assist'\n",
      "Chat model chunk: ' you'\n",
      "Chat model chunk: ' today'\n",
      "Chat model chunk: '?'\n",
      "Chat model chunk: ''\n",
      "__END__\n"
     ]
    }
   ],
   "source": [
    "events = []\n",
    "async for event in llm.astream_events(\"hello\", version=\"v2\"):\n",
    "    if event[\"event\"] == \"on_chat_model_start\":\n",
    "        print(\"Streaming...\")\n",
    "    if event[\"event\"] == \"on_chat_model_stream\":\n",
    "        print(\n",
    "            f\"Chat model chunk: {repr(event['data']['chunk'].content)}\",\n",
    "            flush=True,\n",
    "        )\n",
    "        events.append(event)\n",
    "    if event[\"event\"] == \"on_chat_model_end\":\n",
    "        # It could trigger another process\n",
    "        print(\"__END__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f395ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        instructions: str,\n",
    "        examples: List[dict],\n",
    "        model: str = \"gpt-4o-mini\",\n",
    "        temperature: float = 0.0,\n",
    "    ):\n",
    "\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "        system_prompt = SystemMessage(instructions)\n",
    "        example_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"human\", \"{input}\"),\n",
    "                (\"ai\", \"{output}\"),\n",
    "            ]\n",
    "        )\n",
    "        prompt_template = FewShotChatMessagePromptTemplate(\n",
    "            example_prompt=example_prompt,\n",
    "            examples=examples,\n",
    "        )\n",
    "\n",
    "        self.messages = prompt_template.invoke({}).to_messages()\n",
    "\n",
    "    async def invoke(self, user_message: str) -> AIMessage:\n",
    "        self.messages.append(HumanMessage(user_message))\n",
    "        events = []\n",
    "        chunks = []\n",
    "\n",
    "        # Replacing invoke()\n",
    "        async for event in llm.astream_events(self.messages, version=\"v2\"):\n",
    "            events.append(event)\n",
    "            if event[\"event\"] == \"on_chat_model_start\":\n",
    "                print(\"Streaming...\")\n",
    "            if event[\"event\"] == \"on_chat_model_stream\":\n",
    "                chunk = event[\"data\"][\"chunk\"]\n",
    "                chunks.append(chunk)\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "                if chunk.content.strip() in string.punctuation:\n",
    "                    print(\"\\n\")\n",
    "\n",
    "            if event[\"event\"] == \"on_chat_model_end\":\n",
    "                ai_message = AIMessage(event[\"data\"][\"output\"].content)\n",
    "                self.messages.append(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dbf06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming...\n",
      "\n",
      "\n",
      "The chemical symbol for silver is Ag.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instructions = (\n",
    "    \"Your task is to answer questions about the given text. \"\n",
    "    \"Answer as concisely as possible. \"\n",
    "    \"Use the following format: \"\n",
    "    \"Question: [question] \"\n",
    "    \"Answer: [answer]\"\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"What is the capital of France?\",\n",
    "        \"output\": \"The capital of France is Paris.\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What is the largest planet in our solar system?\",\n",
    "        \"output\": \"The largest planet in our solar system is Jupiter.\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What is the chemical symbol for gold?\",\n",
    "        \"output\": \"The chemical symbol for gold is Au.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "chatbot = ChatBot(\n",
    "    name=\"ChatGPT\",\n",
    "    instructions=instructions,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "await chatbot.invoke(\"What is the chemical symbol for Silver?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499383a6",
   "metadata": {},
   "source": [
    "### Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c4cc8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31949c2f",
   "metadata": {},
   "source": [
    "#### String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac14bc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60607e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = StrOutputParser()\n",
    "\n",
    "parser.invoke(llm.invoke(\"hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd61aa1",
   "metadata": {},
   "source": [
    "#### Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e92581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='2023-10-05T14:23:45.123456Z', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 33, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'stop', 'logprobs': None}, id='run-635b06b1-bdb6-44d1-9728-8c3e215515bd-0', usage_metadata={'input_tokens': 33, 'output_tokens': 17, 'total_tokens': 50})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\n",
    "    \"Output a random datetime in %Y-%m-%dT%H:%M:%S.%fZ. \" \"Don't say anything else\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0663f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 10, 5, 14, 23, 45, 123456)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = DatetimeOutputParser()\n",
    "\n",
    "parser.invoke(\n",
    "    llm.invoke(\n",
    "        \"Output a random datetime in %Y-%m-%dT%H:%M:%S.%fZ. \" \"Don't say anything else\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf3d22",
   "metadata": {},
   "source": [
    "#### Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf7c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='YES', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 16, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'finish_reason': 'stop', 'logprobs': None}, id='run-0e3fcc28-484a-40f8-9e6d-9ba05eeba6c6-0', usage_metadata={'input_tokens': 16, 'output_tokens': 2, 'total_tokens': 18})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Are you an AI? YES or NO only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fc327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = BooleanOutputParser()\n",
    "\n",
    "parser.invoke(input=llm.invoke(\"Are you an AI?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7d07f",
   "metadata": {},
   "source": [
    "#### Structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ae469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PydanticModelInfo(BaseModel):\n",
    "    model_name: Annotated[\n",
    "        str,\n",
    "        Field(\n",
    "            description=\"Paper referred model abbreviation names. Defaults to ''\",\n",
    "            default=None,\n",
    "        ),\n",
    "    ]\n",
    "    publish_year: Annotated[\n",
    "        str,\n",
    "        Field(description=\"When was this model proposed. Defaults to ''\", default=None),\n",
    "    ]\n",
    "    model_type: Annotated[\n",
    "        str,\n",
    "        Field(\n",
    "            description=\"Type of model (e.g., discriminative, generative)\", default=None\n",
    "        ),\n",
    "    ]\n",
    "    application_domain: Annotated[\n",
    "        str,\n",
    "        Field(\n",
    "            description=\"Domain where the model is applied (e.g., antibody design)\",\n",
    "            default=None,\n",
    "        ),\n",
    "    ]\n",
    "    authors: Annotated[\n",
    "        str, Field(description=\"Authors of the paper (e.g., Luo et al.)\", default=None)\n",
    "    ]\n",
    "    model_category: Annotated[\n",
    "        str,\n",
    "        Field(\n",
    "            description=\"Specific category of model (e.g., diffusion model, graph neural network)\",\n",
    "            default=None,\n",
    "        ),\n",
    "    ]\n",
    "    related_models: Annotated[\n",
    "        list[str],\n",
    "        Field(\n",
    "            description=\"Other models mentioned in the same context\",\n",
    "            default_factory=list,\n",
    "        ),\n",
    "    ]\n",
    "    description: Annotated[\n",
    "        str,\n",
    "        Field(\n",
    "            description=\"Brief description of the model's purpose or approach\",\n",
    "            default=None,\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a10164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name='Denoising Diffusion Probabilistic Models' publish_year='2022' model_type='generative' application_domain='antibody design' authors='Luo et al.' model_category='diffusion model' related_models=[] description='Generative models that build an antigen-conditioned generative process of antibody sequences and structure.'\n"
     ]
    }
   ],
   "source": [
    "llm_with_structure = llm.with_structured_output(PydanticModelInfo)\n",
    "\n",
    "structured_output = llm_with_structure.invoke(\n",
    "    \"\"\"\n",
    "    Recent deep learning-based methods for antibody design can be broadly categorized into discrimina-\n",
    "    tive models and generative models. Discriminative models typically leverage graph neural networks\n",
    "    to learn the presentations of antigen structure and to predict the most likely antibody structure and\n",
    "    sequence (Kong et al., 2023; Lin et al., 2024). In contrast, generative models such as the denoising\n",
    "    diffusion probabilistic models (DDPM) (Luo et al., 2022; Martinkus et al., 2024; Tan et al., 2024)\n",
    "    and score-based diffusion models (Zhu et al., 2024; Kulyt˙ e et al., 2024) build an antigen-conditioned\n",
    "    generative process of antibody sequences and structure.\n",
    "    \"\"\"\n",
    ")\n",
    "print(structured_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d253653",
   "metadata": {},
   "source": [
    "####  Dealing with Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45e0d645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'DDPM', 'publish_year': '2022', 'model_type': 'generative', 'application_domain': 'antibody design', 'authors': 'Luo et al.', 'model_category': 'diffusion model', 'related_models': ['DDPM', 'DDPM', 'DDPM'], 'description': 'Denoising diffusion probabilistic models (DDPM) are a type of generative model that learns to generate new data by iteratively denoising a noisy input. In the context of antibody design, DDPMs can be used to generate new antibody sequences and structures that are similar to a given antigen.'}\n"
     ]
    }
   ],
   "source": [
    "misformatted_result = \"{'model_name': 'DDPM', 'publish_year': '2022', 'model_type': 'generative', 'application_domain': 'antibody design', 'authors': 'Luo et al.', 'model_category': 'diffusion model', 'related_models': ['DDPM', 'DDPM', 'DDPM'], 'description': 'Denoising diffusion probabilistic models (DDPM) are a type of generative model that learns to generate new data by iteratively denoising a noisy input. In the context of antibody design, DDPMs can be used to generate new antibody sequences and structures that are similar to a given antigen.'}\"\n",
    "print(misformatted_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9367a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid json output: {'model_name': 'DDPM', 'publish_year': '2022', 'model_type': 'generative', 'application_domain': 'antibody design', 'authors': 'Luo et al.', 'model_category': 'diffusion model', 'related_models': ['DDPM', 'DDPM', 'DDPM'], 'description': 'Denoising diffusion probabilistic models (DDPM) are a type of generative model that learns to generate new data by iteratively denoising a noisy input. In the context of antibody design, DDPMs can be used to generate new antibody sequences and structures that are similar to a given antigen.'}\n"
     ]
    }
   ],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=PydanticModelInfo)\n",
    "\n",
    "try:\n",
    "    parser.parse(misformatted_result)\n",
    "except OutputParserException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b97365f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PydanticModelInfo(model_name='DDPM', publish_year='2022', model_type='generative', application_domain='antibody design', authors='Luo et al.', model_category='diffusion model', related_models=['DDPM', 'DDPM', 'DDPM'], description='Denoising diffusion probabilistic models (DDPM) are a type of generative model that learns to generate new data by iteratively denoising a noisy input. In the context of antibody design, DDPMs can be used to generate new antibody sequences and structures that are similar to a given antigen.')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)\n",
    "\n",
    "new_parser.parse(misformatted_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ae361",
   "metadata": {},
   "source": [
    "### Lang Chain Expression Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c842db5",
   "metadata": {},
   "source": [
    "#### Chaining invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf544e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"What is {tool} used for?\",\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bdde84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AlphaFold is an artificial intelligence program developed by DeepMind that predicts protein structures with high accuracy. It is primarily used for:\\n\\n1. **Protein Structure Prediction**: AlphaFold can predict the three-dimensional structures of proteins based on their amino acid sequences. This is crucial for understanding how proteins function and interact with other molecules.\\n\\n2. **Biological Research**: Researchers use AlphaFold to gain insights into various biological processes, including enzyme function, protein-protein interactions, and the mechanisms of diseases.\\n\\n3. **Drug Discovery**: By providing accurate protein structures, AlphaFold aids in the design of new drugs and therapeutic interventions by helping scientists understand the target proteins involved in diseases.\\n\\n4. **Genomics and Proteomics**: AlphaFold can assist in interpreting genomic data by predicting the structures of proteins encoded by newly sequenced genes, which can help in annotating genomes and understanding gene function.\\n\\n5. **Synthetic Biology**: It can be used to design new proteins with specific functions, which has applications in biotechnology and synthetic biology.\\n\\nOverall, AlphaFold represents a significant advancement in computational biology and has the potential to accelerate research across various fields in life sciences.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(llm.invoke(prompt.invoke({\"tool\": \"Alphafold\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ebe77",
   "metadata": {},
   "source": [
    "#### Runnables\n",
    "\n",
    "```\n",
    "runnables = [prompt, llm, parser]\n",
    "```\n",
    "\n",
    "Runnables can be \n",
    "- executed\n",
    "    - `runnable.invoke()`, \n",
    "    - `runnable.batch()` \n",
    "    - `runnable.stream()`\n",
    "- inspected\n",
    "    - `runnable.get_input_schema()`\n",
    "    - `runnable.get_output_schema()`\n",
    "    - `runnable.config_schema()`\n",
    "- composed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f3303",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableSequence(prompt, llm, parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c8c1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AlphaFold is an artificial intelligence program developed by DeepMind that predicts protein structures with high accuracy. It uses deep learning techniques to analyze the amino acid sequences of proteins and predict their three-dimensional shapes. Understanding protein structures is crucial for various fields, including:\\n\\n1. **Biochemistry and Molecular Biology**: AlphaFold helps researchers understand how proteins function, interact, and contribute to biological processes.\\n\\n2. **Drug Discovery**: By providing insights into protein structures, AlphaFold can aid in the design of new drugs that target specific proteins associated with diseases.\\n\\n3. **Genetics**: It can help interpret the effects of genetic mutations on protein structure and function, which is important for understanding genetic disorders.\\n\\n4. **Synthetic Biology**: Researchers can use AlphaFold to design new proteins with desired functions for applications in biotechnology.\\n\\n5. **Evolutionary Biology**: The program can assist in studying evolutionary relationships by comparing protein structures across different species.\\n\\nOverall, AlphaFold represents a significant advancement in computational biology, enabling researchers to tackle complex questions related to protein structure and function more efficiently.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"tool\": \"Alphafold\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6819c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaFold is an artificial intelligence program developed by DeepMind that predicts protein structures with high accuracy. It is primarily used for:\n",
      "\n",
      "1. **Protein Structure Prediction**: AlphaFold can predict the three-dimensional structures of proteins based on their amino acid sequences. This is crucial for understanding how proteins function and interact with other molecules.\n",
      "\n",
      "2. **Biological Research**: Researchers use AlphaFold to gain insights into various biological processes, including enzyme function, protein-protein interactions, and the mechanisms of diseases.\n",
      "\n",
      "3. **Drug Discovery**: By providing accurate protein structures, AlphaFold aids in the design of new drugs and therapeutic interventions by helping scientists understand the target proteins involved in diseases.\n",
      "\n",
      "4. **Genomics and Proteomics**: AlphaFold can assist in interpreting genomic data by predicting the structures of proteins encoded by newly sequenced genes, which can help in annotating genomes and understanding gene function.\n",
      "\n",
      "5. **Synthetic Biology**: It can be used to design new proteins with specific functions, which has applications in biotechnology and synthetic biology.\n",
      "\n",
      "Overall, AlphaFold represents a significant advancement in computational biology and has the potential to accelerate discoveries in various fields of life sciences."
     ]
    }
   ],
   "source": [
    "for chunk in chain.stream({\"tool\": \"Alphafold\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f37fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlphaFold is an artificial intelligence program developed by DeepMind that predicts protein structures with high accuracy. It is primarily used for:\\n\\n1. **Protein Structure Prediction**: AlphaFold can predict the three-dimensional structures of proteins based on their amino acid sequences. This is crucial for understanding how proteins function and interact with other molecules.\\n\\n2. **Biological Research**: Researchers use AlphaFold to gain insights into various biological processes, including enzyme function, protein-protein interactions, and the mechanisms of diseases.\\n\\n3. **Drug Discovery**: By providing accurate protein structures, AlphaFold aids in the design of new drugs and therapeutic interventions by helping scientists understand the target proteins involved in diseases.\\n\\n4. **Genomics and Proteomics**: AlphaFold can assist in interpreting genomic data by predicting the structures of proteins encoded by newly sequenced genes, which can help in annotating genomes and understanding gene function.\\n\\n5. **Synthetic Biology**: It can be used to design new proteins with specific functions, which has applications in biotechnology and synthetic biology.\\n\\nOverall, AlphaFold represents a significant advancement in computational biology and has the potential to accelerate research across various fields in life sciences.',\n",
       " 'RFDiffusion is a framework designed for generating high-quality images from text prompts using diffusion models. It is particularly useful in the field of artificial intelligence and machine learning for tasks related to image synthesis. The framework leverages the principles of diffusion processes, which iteratively refine random noise into coherent images based on the input text descriptions.\\n\\nKey applications of RFDiffusion include:\\n\\n1. **Text-to-Image Generation**: Creating images that correspond to specific textual descriptions, allowing for creative and artistic expression.\\n\\n2. **Image Editing**: Modifying existing images based on new textual prompts, enabling users to alter aspects of an image while maintaining its overall structure.\\n\\n3. **Art and Design**: Assisting artists and designers in generating concepts and visual ideas quickly, providing inspiration or starting points for further development.\\n\\n4. **Research and Development**: Serving as a tool for researchers exploring the capabilities and limitations of diffusion models in generative tasks.\\n\\nOverall, RFDiffusion represents a significant advancement in the field of generative AI, enabling more sophisticated and nuanced image generation capabilities.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch(\n",
    "    [\n",
    "        {\"tool\": \"Alphafold\"},\n",
    "        {\"tool\": \"RFDiffusion\"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d04d3759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +------------+       \n",
      "      | ChatOpenAI |       \n",
      "      +------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706c496a",
   "metadata": {},
   "source": [
    "**Turn any function into a runnable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29478aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def double(x: int) -> int:\n",
    "    return 2 * x\n",
    "\n",
    "\n",
    "runnable = RunnableLambda(double)\n",
    "runnable.invoke(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff76f3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'double': 6, 'triple': 9}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain = RunnableParallel(\n",
    "    double=RunnableLambda(lambda x: x * 2),\n",
    "    triple=RunnableLambda(lambda x: x * 3),\n",
    ")\n",
    "\n",
    "parallel_chain.invoke(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "70a7df25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+   \n",
      "| Parallel<double,triple>Input |   \n",
      "+------------------------------+   \n",
      "           **        **            \n",
      "         **            **          \n",
      "        *                *         \n",
      "  +--------+          +--------+   \n",
      "  | Lambda |          | Lambda |   \n",
      "  +--------+          +--------+   \n",
      "           **        **            \n",
      "             **    **              \n",
      "               *  *                \n",
      "+-------------------------------+  \n",
      "| Parallel<double,triple>Output |  \n",
      "+-------------------------------+  \n"
     ]
    }
   ],
   "source": [
    "parallel_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70989be",
   "metadata": {},
   "source": [
    "#### LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e4d308e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['tool'], template='What is {tool} used for?')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x115689cc0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11568b5b0>, root_client=<openai.OpenAI object at 0x11559e020>, root_async_client=<openai.AsyncOpenAI object at 0x115689c90>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RunnableSequence(prompt, llm, parser)\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1cc092c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['tool'], template='What is {tool} used for?')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x115689cc0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11568b5b0>, root_client=<openai.OpenAI object at 0x11559e020>, root_async_client=<openai.AsyncOpenAI object at 0x115689c90>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde7d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AlphaFold is an artificial intelligence program developed by DeepMind that predicts protein structures with high accuracy. It is primarily used for:\\n\\n1. **Protein Structure Prediction**: AlphaFold can predict the three-dimensional structures of proteins based on their amino acid sequences, which is a critical aspect of understanding biological functions.\\n\\n2. **Biological Research**: Researchers use AlphaFold to gain insights into protein functions, interactions, and mechanisms, which can aid in various fields such as biochemistry, molecular biology, and pharmacology.\\n\\n3. **Drug Discovery**: By providing accurate protein structures, AlphaFold can facilitate the identification of potential drug targets and the design of new therapeutics.\\n\\n4. **Understanding Diseases**: The program can help in studying the structural basis of diseases caused by protein misfolding or mutations, contributing to the development of treatments.\\n\\n5. **Synthetic Biology**: AlphaFold can assist in designing new proteins with desired functions for applications in biotechnology and synthetic biology.\\n\\nOverall, AlphaFold represents a significant advancement in computational biology, enabling researchers to tackle complex questions related to protein structure and function more effectively.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"tool\": \"Alphafold\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec3241",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "40404a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e192cb2",
   "metadata": {},
   "source": [
    "#### Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9f94643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ArxivLoader(\n",
    "    query=\"llm reasoning with reinforcement learning\",\n",
    "    load_max_docs=1,\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e5df7946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e6299565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46295"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d4e2c999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advancing Reasoning in Large Language Models:\n",
      "Promising Methods and Approaches\n",
      "Avinash Patil\n",
      "avinashpatil@ieee.org\n",
      "ORCID: 0009-0002-6004-370X\n",
      "Abstract—Large Language Models (LLMs) have succeeded\n",
      "remarkably in various natural language processing (NLP) tasks,\n",
      "yet their reasoning capabilities remain a fundamental challenge.\n",
      "While LLMs exhibit impressive fluency and factual recall, their\n",
      "ability to perform complex reasoning—spanning logical deduc-\n",
      "tion, mathematical problem-solving, commonsense inference, and\n",
      "multi-step reasoning—often falls short of human expectations.\n",
      "This survey provides a comprehensive review of emerging tech-\n",
      "niques enhancing reasoning in LLMs. We categorize existing\n",
      "methods into key approaches, including prompting strategies\n",
      "(e.g., Chain-of-Thought reasoning, Self-Consistency, and Tree-\n",
      "of-Thought reasoning), architectural innovations (e.g., retrieval-\n",
      "augmented models, modular reasoning networks, and neuro-\n",
      "symbolic integration), and learning paradigms (e.g., fine-t\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496beb1d",
   "metadata": {},
   "source": [
    "#### Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a4833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Wikipedia page into 177 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split Wikipedia page into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "546a3e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Published': '2025-02-05', 'Title': 'Advancing Reasoning in Large Language Models: Promising Methods and Approaches', 'Authors': 'Avinash Patil', 'Summary': 'Large Language Models (LLMs) have succeeded remarkably in various natural\\nlanguage processing (NLP) tasks, yet their reasoning capabilities remain a\\nfundamental challenge. While LLMs exhibit impressive fluency and factual\\nrecall, their ability to perform complex reasoning-spanning logical deduction,\\nmathematical problem-solving, commonsense inference, and multi-step\\nreasoning-often falls short of human expectations. This survey provides a\\ncomprehensive review of emerging techniques enhancing reasoning in LLMs. We\\ncategorize existing methods into key approaches, including prompting strategies\\n(e.g., Chain-of-Thought reasoning, Self-Consistency, and Tree-of-Thought\\nreasoning), architectural innovations (e.g., retrieval-augmented models,\\nmodular reasoning networks, and neuro-symbolic integration), and learning\\nparadigms (e.g., fine-tuning with reasoning-specific datasets, reinforcement\\nlearning, and self-supervised reasoning objectives). Additionally, we explore\\nevaluation frameworks used to assess reasoning in LLMs and highlight open\\nchallenges, such as hallucinations, robustness, and reasoning generalization\\nacross diverse tasks. By synthesizing recent advancements, this survey aims to\\nprovide insights into promising directions for future research and practical\\napplications of reasoning-augmented LLMs.'}, page_content='Advancing Reasoning in Large Language Models:\\nPromising Methods and Approaches\\nAvinash Patil\\navinashpatil@ieee.org\\nORCID: 0009-0002-6004-370X\\nAbstract—Large Language Models (LLMs) have succeeded\\nremarkably in various natural language processing (NLP) tasks,')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b09e62",
   "metadata": {},
   "source": [
    "#### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dff2088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad68002",
   "metadata": {},
   "source": [
    "#### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b5dd39e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b582217c-bbea-4a9e-af04-1a23c21b67ae',\n",
       " '611f6780-5a83-4f23-8ece-693f5540d7ee',\n",
       " 'dd1562d1-c400-4ae3-ac30-17a27d695726',\n",
       " 'e42682da-0d2e-42c6-91b4-f6ec41d131ae',\n",
       " 'a81ec55d-1c69-45af-acb5-e466635cdf25',\n",
       " '622b7efd-ea9e-4880-b34c-295b992a86f7',\n",
       " '9867358f-fbb0-4907-bf9b-ad6842db7152',\n",
       " 'f8f7e1fa-3e91-404f-8fc0-3e27e56d2041',\n",
       " '2e0a9213-ae1b-479c-9bea-c2fb1ccaa6ef',\n",
       " 'f04eccea-ba74-4d55-9592-1f316d50ac42']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "document_ids[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e925caa",
   "metadata": {},
   "source": [
    "#### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "76a51fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bcee50",
   "metadata": {},
   "source": [
    "#### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc6c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are an assistant for question-answering tasks.\"),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the following pieces of retrieved context to answer the question. \"\n",
    "            \"If you don't know the answer, just say that you don't know. \"\n",
    "            \"Use three sentences maximum and keep the answer concise. \"\n",
    "            \"\\n# Question: \\n-> {question} \"\n",
    "            \"\\n# Context: \\n-> {context} \"\n",
    "            \"\\n# Answer: \",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e9d9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an assistant for question-answering tasks.'),\n",
       " HumanMessage(content=\"Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. \\n# Question: \\n-> ##QUESTION## \\n# Context: \\n-> ##CONTEXT## \\n# Answer: \")]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.invoke({\"context\": \"##CONTEXT##\", \"question\": \"##QUESTION##\"}).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fe94493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    formatted = \"\\n\\n-> \".join(doc.page_content for doc in docs)\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11fb37d",
   "metadata": {},
   "source": [
    "#### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is Program-Aided Language Models (PAL)?\"\n",
    "context = format_docs(retriever.invoke(question))\n",
    "messages = template.invoke({\"question\": question, \"context\": context}).to_messages()\n",
    "answer = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "59433eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. \n",
      "# Question: \n",
      "-> What is Program-Aided Language Models (PAL)? \n",
      "# Context: \n",
      "-> selected based on a scoring or majority selection process\n",
      "[14].\n",
      "D. Program-aided Language Models (PAL)\n",
      "Program-Aided Language Models (PAL) is a technique that\n",
      "enhances a language model’s reasoning capabilities by allow-\n",
      "ing it to call external computational tools—such as Python\n",
      "\n",
      "-> arXiv:2409.12917, 2024.\n",
      "[24] J. Wei et al., “Emergent abilities of large language models,” arXiv\n",
      "preprint arXiv:2206.07682, 2022.\n",
      "[25] L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y. Yang, J. Callan,\n",
      "and G. Neubig, “Pal: Program-aided language models,” in International\n",
      "\n",
      "-> natural language understanding.\n",
      "C. Reasoning in Large Language Models\n",
      "Large Language Models (LLMs) such as GPT-4, PaLM, and\n",
      "LLaMA utilize deep learning architectures, primarily trans-\n",
      "formers, to process and generate human-like text. However, \n",
      "# Answer: \n"
     ]
    }
   ],
   "source": [
    "print(messages[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dfe6b2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Program-Aided Language Models (PAL) is a technique that enhances a language model's reasoning capabilities by enabling it to call external computational tools, such as Python. This allows the model to perform more complex tasks and improve its overall performance in natural language understanding.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 304, 'total_tokens': 356, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'finish_reason': 'stop', 'logprobs': None}, id='run-a0850853-9739-435a-9db0-eead24c68fe6-0', usage_metadata={'input_tokens': 304, 'output_tokens': 52, 'total_tokens': 356})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3724f8e",
   "metadata": {},
   "source": [
    "#### RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35fd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    RunnableParallel(context=retriever | format_docs, question=RunnablePassthrough())\n",
    "    | template\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3153f1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Self-Consistency Prompting is an advanced technique that enhances reasoning accuracy by generating multiple diverse reasoning paths and selecting the most consistent one. It has been shown to significantly improve performance in structured domains like mathematics and logic. This method is part of a broader set of prompting strategies aimed at improving problem-solving and logical inference.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 257, 'total_tokens': 320, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'finish_reason': 'stop', 'logprobs': None}, id='run-889f2093-43e2-4374-bcfd-de3fa8ce1e5c-0', usage_metadata={'input_tokens': 257, 'output_tokens': 63, 'total_tokens': 320})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Self-Consistency Prompting?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367bd981",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f6183fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d285d7",
   "metadata": {},
   "source": [
    "#### Tool creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ff74fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0832fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [multiply]\n",
    "tool_map = {tool.name: tool for tool in tools}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7844ed30",
   "metadata": {},
   "source": [
    "#### Binding Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f432bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cc52bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"3 multiplied by 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf03398",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [SystemMessage(\"You're a helpful assistant\"), HumanMessage(question)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f6a11aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0931d15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_pAZKCH0TCe2IGw0JVpIASM9n', 'function': {'arguments': '{\"a\":3,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 54, 'total_tokens': 72, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4761e33b-34c6-45c5-9423-0b3d0e31af0a-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 2}, 'id': 'call_pAZKCH0TCe2IGw0JVpIASM9n', 'type': 'tool_call'}], usage_metadata={'input_tokens': 54, 'output_tokens': 18, 'total_tokens': 72})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "65bfc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "014d16fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You're a helpful assistant\"),\n",
       " HumanMessage(content='3 multiplied by 2'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_pAZKCH0TCe2IGw0JVpIASM9n', 'function': {'arguments': '{\"a\":3,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 54, 'total_tokens': 72, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4761e33b-34c6-45c5-9423-0b3d0e31af0a-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 2}, 'id': 'call_pAZKCH0TCe2IGw0JVpIASM9n', 'type': 'tool_call'}], usage_metadata={'input_tokens': 54, 'output_tokens': 18, 'total_tokens': 72})]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692ec41",
   "metadata": {},
   "source": [
    "#### Using Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2940020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_pAZKCH0TCe2IGw0JVpIASM9n',\n",
       "  'function': {'arguments': '{\"a\":3,\"b\":2}', 'name': 'multiply'},\n",
       "  'type': 'function'}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.additional_kwargs.get(\"tool_calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ca0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_tool_calls = parse_tool_calls(ai_message.additional_kwargs.get(\"tool_calls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9768e7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 2},\n",
       "  'id': 'call_pAZKCH0TCe2IGw0JVpIASM9n',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928fee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in parsed_tool_calls:\n",
    "    tool_call_id = tool_call[\"id\"]\n",
    "\n",
    "    function_name = tool_call[\"name\"]\n",
    "    arguments = tool_call[\"args\"]\n",
    "\n",
    "    func = tool_map[function_name]\n",
    "\n",
    "    result = func.invoke(arguments)\n",
    "\n",
    "    tool_message = ToolMessage(\n",
    "        content=result,\n",
    "        name=function_name,\n",
    "        tool_call_id=tool_call_id,\n",
    "    )\n",
    "    messages.append(tool_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2caaeb",
   "metadata": {},
   "source": [
    "#### Sending the result back to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f3473907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You're a helpful assistant\"),\n",
       " HumanMessage(content='3 multiplied by 2'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_pAZKCH0TCe2IGw0JVpIASM9n', 'function': {'arguments': '{\"a\":3,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 54, 'total_tokens': 72, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4761e33b-34c6-45c5-9423-0b3d0e31af0a-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 2}, 'id': 'call_pAZKCH0TCe2IGw0JVpIASM9n', 'type': 'tool_call'}], usage_metadata={'input_tokens': 54, 'output_tokens': 18, 'total_tokens': 72}),\n",
       " ToolMessage(content='6', name='multiply', tool_call_id='call_pAZKCH0TCe2IGw0JVpIASM9n')]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "025141b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bae0fc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='3 multiplied by 2 is 6.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 79, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'stop', 'logprobs': None}, id='run-5883e596-8839-4121-a77a-b7be01977f22-0', usage_metadata={'input_tokens': 79, 'output_tokens': 11, 'total_tokens': 90})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e309b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd95a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cef63754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str = \"AI Agent\",\n",
    "        role: str = \"Personal Assistant\",\n",
    "        instructions: str = \"Help users with any question\",\n",
    "        model: str = \"gpt-4o-mini\",\n",
    "        temperature: float = 0.0,\n",
    "        tools: List[StructuredTool] = [],\n",
    "    ):\n",
    "\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.instructions = instructions\n",
    "\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "        self.tools = tools\n",
    "        self.tool_map = {tool.name: tool for tool in tools}\n",
    "        self.memory = [\n",
    "            SystemMessage(\n",
    "                content=f\"You're {self.name}, your role is {self.role}, \"\n",
    "                f\"and you need to {self.instructions} \"\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    def invoke(self, user_message: str):\n",
    "        self.memory.append(HumanMessage(content=user_message))\n",
    "        ai_message = self._invoke_llm()\n",
    "\n",
    "        tool_calls = ai_message.additional_kwargs.get(\"tool_calls\")\n",
    "        if tool_calls:\n",
    "            self._call_tools(tool_calls)\n",
    "            self._invoke_llm()\n",
    "\n",
    "        return self.memory[-1].content\n",
    "\n",
    "    def _invoke_llm(self) -> AIMessage:\n",
    "        llm = self.llm.bind_tools(self.tools)\n",
    "        ai_message = llm.invoke(self.memory)\n",
    "        self.memory.append(ai_message)\n",
    "        return ai_message\n",
    "\n",
    "    def _call_tools(self, tool_calls: List[Dict]):\n",
    "        parsed_tool_calls = parse_tool_calls(tool_calls)\n",
    "        for tool_call in parsed_tool_calls:\n",
    "            tool_call_id = tool_call[\"id\"]\n",
    "            function_name = tool_call[\"name\"]\n",
    "            arguments = tool_call[\"args\"]\n",
    "            func = self.tool_map[function_name]\n",
    "            result = func.invoke(arguments)\n",
    "            tool_message = ToolMessage(\n",
    "                content=result,\n",
    "                name=function_name,\n",
    "                tool_call_id=tool_call_id,\n",
    "            )\n",
    "            self.memory.append(tool_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0757ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bffc731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(tools=[multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0c8f79bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 multiplied by 2 is 4.'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"2 multiplied by 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7083b5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You're AI Agent, your role is Personal Assistant, and you need to Help users with any question \"),\n",
       " HumanMessage(content='2 multiplied by 2'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_du6moZBacMTbkVtczl2XqRpW', 'function': {'arguments': '{\"a\":2,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 69, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-8c7a7aad-7679-41e0-a987-e2d35829a4d7-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 2}, 'id': 'call_du6moZBacMTbkVtczl2XqRpW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 69, 'output_tokens': 18, 'total_tokens': 87}),\n",
       " ToolMessage(content='4', name='multiply', tool_call_id='call_du6moZBacMTbkVtczl2XqRpW'),\n",
       " AIMessage(content='2 multiplied by 2 is 4.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 94, 'total_tokens': 105, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'finish_reason': 'stop', 'logprobs': None}, id='run-9fc3b4aa-f905-4e16-ab44-e03bb3f349d7-0', usage_metadata={'input_tokens': 94, 'output_tokens': 11, 'total_tokens': 105})]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
